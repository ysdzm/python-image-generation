{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GLIGEN の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/py-img-gen/python-image-generation/blob/main/notebooks/5-5-1_gligen.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "参考: https://hf.co/docs/diffusers/api/pipelines/stable_diffusion/gligen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq py-img-gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "dtype = torch.float16\n",
    "seed = 42\n",
    "\n",
    "image_w, image_h = 512, 512\n",
    "\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "# error ログを無視する\n",
    "logger_name = \"diffusers.models.modeling_utils\"\n",
    "logging.getLogger(logger_name).setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## サンプル画像の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "input_image = load_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/livingroom_modern.png\"\n",
    ")\n",
    "input_image = input_image.resize((image_w, image_h))\n",
    "input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## テキスト指示と inpainting による対象領域に対するオジリナル画像への物体の挿入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### GLIGEN inpainting pipeline の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionGLIGENPipeline\n",
    "\n",
    "model_id = \"masterful/gligen-1-4-inpainting-text-box\"\n",
    "\n",
    "pipe_inpainting = (\n",
    "    StableDiffusionGLIGENPipeline.from_pretrained(\n",
    "        model_id, torch_dtype=dtype\n",
    "    )\n",
    ")\n",
    "pipe_inpainting = pipe_inpainting.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### inpaint 対象の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import ImageDraw\n",
    "from PIL.Image import Image as PilImage\n",
    "\n",
    "Bbox = Tuple[int, int, int, int]\n",
    "\n",
    "\n",
    "def draw_bboxes_phrases(\n",
    "    bboxes: List[Bbox], phrases: List[str], image: PilImage\n",
    ") -> PilImage:\n",
    "    \"\"\"Draw bounding boxes and phrases on the image.\n",
    "\n",
    "    Args:\n",
    "        bboxes (List[Bbox]): List of bounding boxes.\n",
    "        phrases (List[str]): List of phrases.\n",
    "        image (PilImage): Input image.\n",
    "\n",
    "    Returns:\n",
    "        PilImage: Image with bounding boxes and phrases.\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    assert len(bboxes) == len(phrases)\n",
    "    for bbox, phrase in zip(bboxes, phrases):\n",
    "        draw.rectangle(bbox, outline=\"red\")\n",
    "        draw.text((bbox[0], bbox[1]), phrase, fill=\"red\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "prompt = \"a birthday cake\"\n",
    "phrases = [\"a birthday cake\"]\n",
    "bboxes = [[137, 312, 244, 368]]\n",
    "\n",
    "bbox_image = draw_bboxes_phrases(\n",
    "    bboxes=bboxes, phrases=phrases, image=input_image\n",
    ")\n",
    "bbox_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### inpainting pipeline による生成と結果の確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### bbox の正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_bboxes(\n",
    "    bboxes: List[Bbox], w: int, h: int\n",
    ") -> List[Bbox]:\n",
    "    \"\"\"Normalize bounding boxes to [0, 1].\n",
    "\n",
    "    Args:\n",
    "        bboxes (List[Bbox]): List of bounding boxes.\n",
    "        w (int): Image width.\n",
    "        h (int): Image height.\n",
    "\n",
    "    Returns:\n",
    "        List[Bbox]: Normalized bounding boxes.\n",
    "    \"\"\"\n",
    "    bboxes_np = np.array(bboxes, dtype=float)\n",
    "    bboxes_np[:, 0::2] /= w\n",
    "    bboxes_np[:, 1::2] /= h\n",
    "    return bboxes_np.tolist()\n",
    "\n",
    "\n",
    "bboxes_normalized = normalize_bboxes(\n",
    "    bboxes, w=image_w, h=image_h\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### 画像生成と結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe_inpainting(\n",
    "    prompt=prompt,\n",
    "    gligen_inpaint_image=input_image,\n",
    "    gligen_boxes=bboxes_normalized,\n",
    "    gligen_phrases=phrases,\n",
    "    gligen_scheduled_sampling_beta=1,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(seed),\n",
    ").images[0]\n",
    "\n",
    "bbox_image = draw_bboxes_phrases(\n",
    "    bboxes=bboxes, phrases=phrases, image=image\n",
    ")\n",
    "bbox_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "make_image_grid(\n",
    "    [input_image, image, bbox_image], rows=1, cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## テキストと領域指示による新たな画像の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### GLIGEN generation pipeline の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"masterful/gligen-1-4-generation-text-box\"\n",
    "\n",
    "pipe_gen = StableDiffusionGLIGENPipeline.from_pretrained(\n",
    "    model_id, torch_dtype=dtype\n",
    ")\n",
    "pipe_gen = pipe_gen.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### generation pipeline による生成と結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "prompt = \"a waterfall and a modern high speed train running through the tunnel in a beautiful forest with fall foliage\"\n",
    "\n",
    "phrases = [\n",
    "    \"a waterfall\",\n",
    "    \"a modern high speed train running through the tunnel\",\n",
    "]\n",
    "bboxes = [\n",
    "    [71, 105, 218, 363],\n",
    "    [254, 222, 436, 372],\n",
    "]\n",
    "\n",
    "blank_image = Image.new(\n",
    "    \"RGB\", (image_w, image_h), color=\"white\"\n",
    ")\n",
    "\n",
    "bbox_image = draw_bboxes_phrases(\n",
    "    bboxes=bboxes, phrases=phrases, image=blank_image\n",
    ")\n",
    "bboxes_normalized = normalize_bboxes(\n",
    "    bboxes, w=image_w, h=image_h\n",
    ")\n",
    "\n",
    "image = pipe_gen(\n",
    "    prompt=prompt,\n",
    "    gligen_phrases=phrases,\n",
    "    gligen_boxes=bboxes_normalized,\n",
    "    gligen_scheduled_sampling_beta=1,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.manual_seed(seed),\n",
    ").images[0]\n",
    "\n",
    "make_image_grid([bbox_image, image], rows=1, cols=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
