{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DDPM (Denoising Diffusion Probabilistic Models) の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/py-img-gen/python-image-generation/blob/main/notebooks/3-2-1_ddpm.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "参考: https://github.com/JeongJiHeon/ScoreDiffusionModel/blob/main/DDPM/DDPM_MNIST.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq py-img-gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "current_dir = pathlib.Path.cwd()\n",
    "project_dir = current_dir / \"data\" / \"ddpm\"\n",
    "project_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Created a directory: {project_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 設定の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from py_img_gen.trainers import TrainDDPMConfig\n",
    "\n",
    "train_config = TrainDDPMConfig(output_dir=project_dir)\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from py_img_gen.trainers import EvalConfig\n",
    "\n",
    "eval_config = EvalConfig()\n",
    "print(eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from py_img_gen.trainers import DDPMModelConfig\n",
    "\n",
    "model_config = DDPMModelConfig()\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## シードの固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(seed=train_config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Denoiser の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "unet = UNet2DModel(\n",
    "    **asdict(model_config),\n",
    ")\n",
    "unet = unet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Noise Scheduler の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=train_config.num_timesteps,\n",
    "    beta_start=train_config.beta_1,\n",
    "    beta_end=train_config.beta_T,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Optimizer の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(\n",
    "    unet.parameters(), lr=train_config.lr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_img_gen.trainers import (\n",
    "    get_simple_resize_transforms,\n",
    ")\n",
    "\n",
    "transform = get_simple_resize_transforms(\n",
    "    sample_size=model_config.sample_size\n",
    ")\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=project_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=train_config.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=train_config.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## DDPM の訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 1 イテレーションの訓練プロセスを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from diffusers.utils import make_image_grid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train_iteration(\n",
    "    train_config: TrainDDPMConfig,\n",
    "    unet: UNet2DModel,\n",
    "    noise_scheduler: DDPMScheduler,\n",
    "    optim: torch.optim.Optimizer,\n",
    "    data_loader: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    with tqdm(\n",
    "        total=len(data_loader),\n",
    "        desc=\"Iteration\",\n",
    "        leave=False,\n",
    "    ) as pbar:\n",
    "        for x, _ in data_loader:\n",
    "            bsz = x.shape[0]\n",
    "            x = x.to(device)\n",
    "\n",
    "            t = torch.randint(\n",
    "                low=0,\n",
    "                high=train_config.num_timesteps,\n",
    "                size=(bsz,),\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            z = torch.randn_like(x)\n",
    "            x_noisy = noise_scheduler.add_noise(x, z, t)\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            z_pred = unet(x_noisy, t).sample\n",
    "            loss = F.mse_loss(z_pred, z)\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            pbar.set_postfix(loss=loss.detach().item())\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### エポック全体の訓練プロセスを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_config: TrainDDPMConfig,\n",
    "    eval_config: EvalConfig,\n",
    "    unet: UNet2DModel,\n",
    "    noise_scheduler: DDPMScheduler,\n",
    "    optim: torch.optim.Optimizer,\n",
    "    data_loader: DataLoader,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    # UNet を訓練モードに設定\n",
    "    unet.train()  # type: ignore[attr-defined]\n",
    "\n",
    "    for epoch in tqdm(\n",
    "        range(train_config.num_epochs), desc=\"Epoch\"\n",
    "    ):\n",
    "        train_iteration(\n",
    "            train_config=train_config,\n",
    "            unet=unet,\n",
    "            noise_scheduler=noise_scheduler,\n",
    "            optim=optim,\n",
    "            data_loader=data_loader,\n",
    "            device=device,\n",
    "        )\n",
    "        images = inference(\n",
    "            unet=unet,\n",
    "            noise_scheduler=noise_scheduler,\n",
    "            train_config=dataclasses.replace(\n",
    "                train_config,\n",
    "                batch_size=eval_config.num_generate_images,\n",
    "            ),\n",
    "        )\n",
    "        image = make_image_grid(\n",
    "            images=images,  # type: ignore\n",
    "            rows=eval_config.num_grid_rows,\n",
    "            cols=eval_config.num_grid_cols,\n",
    "        )\n",
    "        image.save(project_dir / f\"{epoch=}.png\")\n",
    "        image.save(project_dir / \"validation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "from diffusers.schedulers.scheduling_ddpm import (\n",
    "    DDPMSchedulerOutput,\n",
    ")\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from PIL.Image import Image as PilImage\n",
    "from py_img_gen.utils import decode_images\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(\n",
    "    unet: UNet2DModel,\n",
    "    noise_scheduler: DDPMScheduler,\n",
    "    train_config: TrainDDPMConfig,\n",
    "    only_final: bool = True,\n",
    ") -> Union[List[PilImage], List[List[PilImage]]]:\n",
    "    # UNet を評価モードに設定\n",
    "    unet.eval()  # type: ignore[attr-defined]\n",
    "    # ノイズスケジューラにタイムステップを設定\n",
    "    noise_scheduler.set_timesteps(\n",
    "        train_config.num_timesteps\n",
    "    )\n",
    "    # 再現性のために推論用の乱数生成器を設定\n",
    "    generator = torch.manual_seed(train_config.seed)\n",
    "\n",
    "    # ノイズの形状を設定してからランダムノイズを生成\n",
    "    x_shape = (\n",
    "        train_config.batch_size,\n",
    "        unet.config.in_channels,\n",
    "        unet.config.sample_size,\n",
    "        unet.config.sample_size,\n",
    "    )\n",
    "    x = randn_tensor(\n",
    "        x_shape, generator=generator, device=unet.device\n",
    "    )\n",
    "\n",
    "    # 逆拡散過程を実行\n",
    "    images, timesteps = [], noise_scheduler.timesteps\n",
    "    for t in tqdm(\n",
    "        timesteps, desc=\"Generating...\", leave=False\n",
    "    ):\n",
    "        # ノイズ `z` を予測し、`z_pred` として取得\n",
    "        z_pred = unet(x, t).sample\n",
    "\n",
    "        # 一つ前の状態を計算: x_{t} -> x_{t-1}\n",
    "        output = noise_scheduler.step(\n",
    "            model_output=z_pred,\n",
    "            timestep=t,  # type: ignore\n",
    "            sample=x,\n",
    "            generator=generator,\n",
    "        )\n",
    "        x = (\n",
    "            output.prev_sample\n",
    "            if isinstance(output, DDPMSchedulerOutput)\n",
    "            else output[0]\n",
    "        )\n",
    "        if not only_final:\n",
    "            images.append(decode_images(x))\n",
    "\n",
    "    return decode_images(x) if only_final else images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 訓練の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    train_config=train_config,\n",
    "    eval_config=eval_config,\n",
    "    unet=unet,\n",
    "    noise_scheduler=noise_scheduler,\n",
    "    optim=optim,\n",
    "    data_loader=data_loader,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## DDPM の推論"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 推論過程のアニメーションの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from py_img_gen import inferencers\n",
    "\n",
    "ani = inferencers.animation_inference(\n",
    "    train_config=train_config,\n",
    "    eval_config=eval_config,\n",
    "    unet=unet,\n",
    "    noise_scheduler=noise_scheduler,\n",
    ")\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### diffusers のパイプラインによる推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline\n",
    "\n",
    "pipe = DDPMPipeline(unet=unet, scheduler=noise_scheduler)\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\n",
    "    num_inference_steps=train_config.num_timesteps,\n",
    "    batch_size=eval_config.num_generate_images,\n",
    "    generator=torch.manual_seed(train_config.seed),\n",
    ")\n",
    "image = make_image_grid(\n",
    "    images=output.images,\n",
    "    rows=eval_config.num_grid_rows,\n",
    "    cols=eval_config.num_grid_cols,\n",
    ")\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
